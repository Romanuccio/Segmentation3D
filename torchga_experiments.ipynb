{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47cb8041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchga.torchga import GeometricAlgebra\n",
    "from torchga.layers import (\n",
    "    GeometricProductDense,\n",
    "    TensorToGeometric,\n",
    "    GeometricProductConv1D,\n",
    "    GeometricProductElementwise,\n",
    "    GeometricSandwichProductDense,\n",
    "    GeometricSandwichProductElementwise\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dce50c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 64])\n"
     ]
    }
   ],
   "source": [
    "batch = 4\n",
    "modalities = 3\n",
    "test_input = torch.rand([batch, modalities, 4, 4, 4]) # batch, modalities, 4x4x4\n",
    "test_input = test_input.flatten(start_dim = 2) # flat embeddings\n",
    "embedding_length = test_input.shape[-1]\n",
    "algebra_metric = [1, 1, 1]\n",
    "algebra = GeometricAlgebra(algebra_metric)\n",
    "embedding_indices = [1, 2, 3]\n",
    "to_ga_embeddings = nn.ModuleList()\n",
    "\n",
    "# prepare embedding sublayers\n",
    "for index in embedding_indices:\n",
    "    to_ith_blade = TensorToGeometric(algebra, torch.tensor(index))\n",
    "    to_ga_embeddings.append(to_ith_blade)\n",
    "    \n",
    "print(test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "206dca8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([4, 64]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = [t.squeeze(1) for t in torch.chunk(test_input, chunks=test_input.shape[0], dim=1)]\n",
    "len(embeddings), embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f52bda18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 64, 8]), 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ga_embedding_vectors = [\n",
    "                embedding_ith(emb[..., None])\n",
    "                for embedding_ith, emb in zip(to_ga_embeddings, embeddings)\n",
    "            ]\n",
    "ga_embedding_vectors[0].shape, len(ga_embedding_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3c5eec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.1478, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ga_embedding_vectors[1][3, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b4a5343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 64, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 64, 8]),\n",
       " tensor([0.0000, 0.1690, 0.0304, 0.0791, 0.0000, 0.0000, 0.0000, 0.0000]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ga_embedding = torch.stack(ga_embedding_vectors, dim=0)\n",
    "print(ga_embedding.shape)\n",
    "ga_embedding = ga_embedding.sum(dim=0)\n",
    "ga_embedding.shape, ga_embedding[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bb776f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding inputs are of shape torch.Size([4, 64, 8])\n",
      "\n",
      "geometric product dense block produces torch.Size([4, 64, 8]), example\n",
      "tensor([ 0.0335,  0.0837,  0.1045,  0.4523, -0.2594,  0.1548,  0.3612,  0.0000],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "geometric product conv1d block produces torch.Size([1, 64, 8]), example\n",
      "tensor([ 0.0159,  0.0263,  0.1174, -0.1688, -0.0539, -0.1391, -0.1785, -0.1962],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "geometric product elementwise block produces torch.Size([4, 64, 8]), example\n",
      "tensor([-0.0610,  0.0238,  0.0043,  0.0111, -0.0109,  0.0018,  0.0054,  0.0000],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "geometric product sandwich dense block produces torch.Size([4, 64, 8]), example\n",
      "tensor([-9.8562e-02,  2.1833e-02, -4.2696e-03,  9.7732e-03,  2.4745e-09,\n",
      "        -3.5034e-09,  3.4506e-09, -1.0405e-09], grad_fn=<SliceBackward0>)\n",
      "geometric product sandwich dense elementwise block produces torch.Size([4, 64, 8]), example\n",
      "tensor([-5.1293e-04, -7.1052e-04,  1.3378e-04,  1.9419e-04,  4.6566e-10,\n",
      "        -9.3132e-10,  5.8208e-11, -2.4738e-10], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"embedding inputs are of shape {ga_embedding.shape}\\n\")\n",
    "weight_blade_indices = torch.tensor([0, 1, 2, 3])\n",
    "# GeometricProductDense,\n",
    "processing_block = GeometricProductDense(\n",
    "    algebra,\n",
    "    embedding_length,\n",
    "    embedding_length,\n",
    "    blade_indices_kernel=weight_blade_indices,\n",
    "    activation=\"tanh\",\n",
    "    use_bias=False,\n",
    ")\n",
    "output = processing_block(ga_embedding)\n",
    "print(\n",
    "    f\"geometric product dense block produces {output.shape}, example\\n{output[0,0,:]}\"\n",
    ")\n",
    "# GeometricProductConv1D,\n",
    "# this shit is crazy\n",
    "processing_block = GeometricProductConv1D(\n",
    "    algebra,\n",
    "    num_input_filters=embedding_length,\n",
    "    num_output_filters=embedding_length,\n",
    "    kernel_size=3,\n",
    "    stride=3,\n",
    "    padding=None,\n",
    "    blade_indices_kernel=weight_blade_indices,\n",
    "    activation=\"tanh\",\n",
    "    use_bias=False,\n",
    ")\n",
    "output = processing_block(ga_embedding)\n",
    "print(\n",
    "    f\"geometric product conv1d block produces fucked up {output.shape}, example\\n{output[0,0,:]}\"\n",
    ")\n",
    "# GeometricProductElementwise,\n",
    "processing_block = GeometricProductElementwise(\n",
    "    algebra, embedding_length, embedding_length, weight_blade_indices, activation=\"tanh\", use_bias=False\n",
    ")\n",
    "output = processing_block(ga_embedding)\n",
    "print(\n",
    "    f\"geometric product elementwise block produces {output.shape}, example\\n{output[0,0,:]}\"\n",
    ")\n",
    "# GeometricSandwichProductDense\n",
    "processing_block = GeometricSandwichProductDense(\n",
    "    algebra, embedding_length, embedding_length, weight_blade_indices, activation=\"tanh\", use_bias=False\n",
    ")\n",
    "output = processing_block(ga_embedding)\n",
    "print(\n",
    "    f\"geometric product sandwich dense block produces {output.shape}, example\\n{output[0,0,:]}\"\n",
    ")\n",
    "# GeometricSandwichProductElementwise\n",
    "processing_block = GeometricSandwichProductElementwise(\n",
    "    algebra, embedding_length, embedding_length, weight_blade_indices, activation=\"tanh\", use_bias=False\n",
    ")\n",
    "output = processing_block(ga_embedding)\n",
    "print(\n",
    "    f\"geometric product sandwich dense elementwise block produces {output.shape}, example\\n{output[0,0,:]}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
